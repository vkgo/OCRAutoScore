[p1]
prompt: p1
batch_size: 32
data_sample_rate: 1.0
r_dropout: 0
chunk_sizes: 90_30_130_10
cuda: 1
train_epoch: 128
# microsoft/deberta-v3-base bert-base-uncased
PLM: microsoft/deberta-v3-base
# PLM: bert-base-uncased
lr_0: 1e-4
lr_1: 1e-4
# lossfunction weight [MSE cos rankloss]
w1: 40
w2: 100
w3: 1